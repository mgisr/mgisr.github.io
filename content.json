{"meta":{"title":"mgisr's blog","subtitle":"Algorithm","description":"稻花香里说丰年，听取WA声一片","author":"mgisr","url":"https://mgisr.github.io","root":"/"},"pages":[{"title":"tags","date":"2018-09-30T10:23:38.000Z","updated":"2021-04-23T14:05:46.430Z","comments":true,"path":"tags/index.html","permalink":"https://mgisr.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-09-30T09:25:30.000Z","updated":"2021-04-23T14:05:09.098Z","comments":true,"path":"categories/index.html","permalink":"https://mgisr.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"浅谈Fibonacci数列","slug":"浅谈Fibonacci数列","date":"2021-04-23T14:31:19.000Z","updated":"2021-04-23T14:48:05.059Z","comments":true,"path":"2021/04/23/浅谈Fibonacci数列/","link":"","permalink":"https://mgisr.github.io/2021/04/23/%E6%B5%85%E8%B0%88Fibonacci%E6%95%B0%E5%88%97/","excerpt":"","text":"浅谈Fibonacci数列Fibonacci数列定义Fibonacci数列是数学家$Leonardo\\;Fibonacci$在研究兔子的繁衍问题时提出的，该数列的表述如下： 第一个月初有一对刚诞生的兔子 第二个月之后（第三个月初）它们可以生育 每月每对可生育的兔子会诞生一对新兔子 兔子永不死去 如果我们假设$Fn = a,F{n + 1} = b$，则$F_{n +2}$的值显然是由两部分组成的，即： 第$n + 1$月留存的兔子数，即$b$。 第$n + 1$月可以繁衍的兔子生下的兔子数 $ + $ 第$n$月新诞生的兔子生下的兔子数 $=$ $a$。 Fibonacci数列的递推式因此我们可以得到Fibonacci数列的递推式： {\\large \\left\\{\\begin{matrix} F_0 & = & 1\\\\ F_1 & = & 1\\\\ F_n & = & F_{n - 1} + F_{n - 2} & (n \\ge 2) \\end{matrix}\\right.}根据这一递推式，我们可以在$\\Theta(n)$的时间下求出Fibonacci数列的第$n$项。 但对于这么简单的问题，显然竞赛不会只考的这么简单。既然大家都会$\\Theta(n)$的递推，那我就把数据范围改成$\\Theta(n)$无法通过的范围就好了。 如何优化一看到线性递推因为太简单所以要加大数据范围，我们可以自然地想到另一个与他类似的东西——幂。 幂运算的递推同样具有与Fibonacci数列同样的时间复杂度，但因为数据范围过大的问题，我们发明了用于优化幂运算的算法——快速幂。那我们能不能针对Fibonacci数列，构造一种类似于快速幂的算法用来加速递推呢？答案是可以。下面给出该算法的定义及过程： 我们先构造Fibonacci数列的答案矩阵： {\\large \\begin{bmatrix} F_{n + 1} \\\\ F_n \\end{bmatrix}}显然这个矩阵可以通过: {\\large \\begin{bmatrix} F_{n} \\\\ F_{n - 1} \\end{bmatrix}}得到。 构造状态转移矩阵： {\\large A = \\begin{bmatrix} 1 & 1 \\\\ 1 & 0 \\end{bmatrix}}易得： {\\large \\begin{bmatrix} F_{n + 1} \\\\ F_n \\end{bmatrix} = A \\times \\begin{bmatrix} F_{n} \\\\ F_{n - 1} \\end{bmatrix}}我们将上式分解可得： {\\large \\begin{array}{l} \\begin{bmatrix} F_{n + 1} \\\\ F_n \\end{bmatrix} & = & A & \\times & \\begin{bmatrix} F_{n} \\\\ F_{n - 1} \\end{bmatrix} \\\\ & = & A^2 & \\times & \\begin{bmatrix} F_{n-1} \\\\ F_{n - 2} \\end{bmatrix} \\\\ & \\vdots & \\\\ & = & A^n & \\times & \\begin{bmatrix} F_1 \\\\ F_{0} \\end{bmatrix} \\end{array}}观察易得： {\\large \\begin{bmatrix} F_{n} \\\\ F_{n - 1} \\end{bmatrix} = A^{n - 1} \\times \\begin{bmatrix} F_{1} \\\\ F_{0} \\end{bmatrix}}对于$A^{n - 1}$，我们可用快速幂方法，在$O(log\\;n)$的时间内求出，所以矩阵快速幂可以将线性递推优化至$O(log \\; n)$。 下面给出矩阵快速幂优化Fibonacci数列递推的代码实现： #include &lt;iostream> #include &lt;vector> using namespace std; vector&lt;vector&lt;int>> A&#123;&#123;1, 1&#125;, &#123;1, 0&#125;&#125;; vector&lt;vector&lt;int>> mul(vector&lt;vector&lt;int>> &amp;A, vector&lt;vector&lt;int>> &amp;B) &#123; int s = 0; int n = A.size(), m = B[0].size(); vector&lt;vector&lt;int>> C(n, vector&lt;int>(m, 0)); for (int i = 0; i &lt; n; i++) &#123; for (int k = 0; k &lt; n; k++) &#123; s = A[i][k]; for (int j = 0; j &lt; m; j++) C[i][j] += s * B[k][j]; &#125; &#125; return C; &#125; vector&lt;vector&lt;int>> qmatpow(int b) &#123; int n = A.size(); vector&lt;vector&lt;int>> C = A; while (b) &#123; if (b &amp; 1) C = mul(A, C); b >>= 1; A = mul(A, A); &#125; return C; &#125; int fib(int n) &#123; vector&lt;vector&lt;int>> ans = qmatpow(n - 1); return ans[0][0]; &#125; int main(int argc, const char *argv[]) &#123; ios::sync_with_stdio(false); cin.tie(0), cout.tie(0); int n; cin >> n; cout &lt;&lt; fib(n - 1) &lt;&lt; endl; return 0; &#125; 一些有趣的性质 $\\large \\sum{i = 1}^{n}F_i = F{n + 2} - 1$ 证明：我们观察下面这个式子： {\\large F_{n + 1} = F_n + F_{n - 1}}变形得： {\\large F_n = F_{n + 1} - F_{N - 1}}观察下面这组式子： {\\large \\begin{array}{l} F_1 & = & F_2 & - & F_0 \\\\ F_2 & = & F_3 & - & F_1 \\\\ & \\vdots & \\\\ F_{n - 1} & = & F_{n} & - & F_{n - 2} \\\\ F_n & = & F_{n + 1} & - & F_{n - 1} \\end{array}}两侧分别求和可得： {\\large \\sum_{i = 1}^{n}F_i = F_{n + 1} + F_n - F_1 - F_0}即： {\\large \\sum_{i = 1}^{n}F_i = F_{n + 2} - 1}证毕。 根据这一性质，我们在对Fibonacci数列求和时，可以不必对前$n$项累加，而只用求第$n + 2$项即可。 $\\large F{m + n} = F_m \\cdot F{n + 1} + F{m - 1} \\cdot F{n}$ 证明：当$m = 1, n = 0$时：显然成立。 假设至第$n$项时，等式成立，则有： {\\large\\begin{array}{l} F_mF_{n + 1} + F_{m - 1}F_n & = & F_m(F_{n - 1} + F_{n}) & + & F_{m - 1}(F_{n - 2}F_{n - 1}) \\\\ & = & (F_mF_n + F_{m - 1}F_{n - 1}) & + & (F_mF_{n - 1} + F_{m - 1}F_{n - 2}) \\\\ & = & F_{m + n - 1} & + & F_{m + n - 2} \\\\ & = & F_{m + n} \\end{array}}证毕。 应用：根据这一性质，我们可以得到一种新的递推$F_n$的方法。首先，我们令$m = n$，则有： {\\large \\begin{array}{l} F_{2n} & = & F_n \\cdot F_{n + 1} + F_{n - 1} \\cdot F_n \\\\ & = & F_n(F_{n + 1} + F_{n - 1}) \\\\ & = & F_n(2F_{n + 1} - F_{n - 1}) \\\\ F_{2n + 1} & = & F_{n + 1}^{2} + F_n^2 \\end{array} \\\\}由此式，我们可以写出一种时间复杂度与矩阵快速幂相同，但常数比其小的算法（无矩阵乘法消耗）: using pii = pair&lt;int, int>; pii fib(int n) &#123; if (n == 0) return &#123;0, 1&#125;; pii p = fib(n >> 1); int a = p.first * (2 * p.second - p.first); int b = p.first * p.first + p.second * p.second; if (n &amp; 1) return &#123;b, a + b&#125;; else return &#123;a, b&#125;; &#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://mgisr.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数论","slug":"数论","permalink":"https://mgisr.github.io/tags/%E6%95%B0%E8%AE%BA/"}]},{"title":"Lucas定理","slug":"浅谈Lucas定理","date":"2021-04-16T12:51:52.000Z","updated":"2021-04-16T12:56:43.903Z","comments":true,"path":"2021/04/16/浅谈Lucas定理/","link":"","permalink":"https://mgisr.github.io/2021/04/16/%E6%B5%85%E8%B0%88Lucas%E5%AE%9A%E7%90%86/","excerpt":"浅谈Lucas定理问题引出组合数求模一直是大大小小的算法竞赛中出现频率比较高的考点。我们知道组合数的定义为： {\\large C_n^m = \\frac{n!}{m!(n - m)!}}如果问题的规模很小的话，我们可以直接迭代求解。但事实上当$21! = 51090942171709440000$就已经超出了$C/C++$等语言所能表示的数的最大范围。","text":"浅谈Lucas定理问题引出组合数求模一直是大大小小的算法竞赛中出现频率比较高的考点。我们知道组合数的定义为： {\\large C_n^m = \\frac{n!}{m!(n - m)!}}如果问题的规模很小的话，我们可以直接迭代求解。但事实上当$21! = 51090942171709440000$就已经超出了$C/C++$等语言所能表示的数的最大范围。 所以，对于 {\\large C_n^m = \\frac{n!}{m!(n - m)!} \\quad mod \\;\\; p}这一问题，我们无法先求出组合数再对$p$取模。根据杨辉三角的性质，我们易得一个关于$C_n^m$的递推式： {\\large C_n^m = C_{n - 1}^{m - 1} + C_{n - 1}^{m}}同时又因为取模运算的性质： {\\large (A + B) \\;\\; mod \\;\\; p \\equiv A \\;\\; mod \\;\\; p \\;\\; + \\;\\; B \\;\\; mod \\;\\; p}我们可以利用这个递推式，在$O(n^2)$的时间内得到该问题的解。这对于一般的应用似乎已经足够了，可是在算法竞赛中$O(n^2) \\equiv force \\equiv TLE$。所以说，对于这一时间复杂度我们是不能接受的。 现在让我们回到最初的问题： {\\large C_n^m = \\frac{n!}{m!(n - m)!} \\quad mod \\;\\; p}我们发现这个表达式中用到了除法，我的上一篇文章《乘法逆元》中提到过，除法是不满足取模的分配律的，所以数学家们发明了逆元这种东西，将除法转变为乘法。因此上式可化为： {\\large C_n^m = n! \\times inv(m!) \\times inv[(n - m)!] \\quad mod \\;\\; p}模$p$意义下的阶乘和逆元都可以以$O(n)$的时间求得（《乘法逆元》中提到的线性求逆），所以对于每个$C_n^m$我们只需要$O(1)$的时间查询。 这似乎是很美好的，但我们考虑一个问题：如果$p &lt; n$呢？我们知道的是，一个数在模$p$意义下的逆元存在的充分必要条件是$gcd(n, p) = 1$。如果$p &lt; n$的话，我们就无法保证$p \\nmid n$，同时也就无法保证$n^{-1}$存在。这时我们依旧可以利用从杨辉三角得出的递推式来求解，但我们已经说过了，递推式$O(n^2)$的时间复杂度是我们不能接受的。 为了解决这个问题，我们就要引出今天的主角——Lucas定理。 Lucas定理的定义对于非负整数$n, m$以及质数$p$： {\\large C_n^m \\equiv \\prod_{i = 0}^{k}C_{n_i}^{m_i} \\quad mod \\;\\; p}其中： {\\large \\begin{array}{c} n & = & n_kp^k & + & \\cdots & + & n_1p & + & n_0 \\\\ m & = & m_kp^k & + & \\cdots & + & m_1p & + & m_0 \\end{array}}也就是$n$和$m$的$p$进制展开。 但在实际使用的时候，我们大多是使用一个与上式等价的式子： {\\large C_n^m = C_{n \\; mod \\; p}^{m \\; mod \\; p} \\times C_{ \\left \\lfloor n / p \\right \\rfloor}^{\\left \\lfloor m / p \\right \\rfloor} \\quad mod \\;\\; p}特别的，当$n &lt; m$时，规定$C_n^m = 0$。 利用这个式子，我们可以递归求解，递归的出口显然是$m = 0$，下面给出伪代码实现： {\\large \\begin{array}{1} \\text{LUCAS}(n, m, p) \\\\ \\begin{array}{2} 1 & \\textbf{if } \\; n = 0 \\\\ 2 & \\qquad \\textbf{return } \\; 0 \\\\ 3 & ans \\gets LUCAS(\\left \\lfloor \\frac{n}{p} \\right \\rfloor, \\left \\lfloor \\frac{m}{p} \\right \\rfloor, p) \\times C(n \\; mod \\; p, m \\; mod \\; p, p) \\;\\; mod \\;\\; p\\\\ 4 & \\textbf{return } \\; ans \\\\ \\end{array} \\\\ \\\\ \\text{C}(n, m, p) \\\\ \\begin{array}{2} 1 & \\textbf{if } \\; n < m \\\\ 2 & \\qquad \\textbf{return } \\; 0 \\\\ 3 & ans \\gets fac[n] \\times inv[fac[m]] \\times inv[fac[n - m]] \\;\\; mod \\;\\; p \\\\ 4 & \\textbf{return } \\; ans \\end{array} \\end{array}}对于阶乘$fac$以及逆元$inv$，我们只需要预处理$p$以内的即可，因为$n \\; mod \\; p, m \\; mod \\; p$的剩余系均属于$[0, p - 1]$。 关于Lucas定理及其等价式的证明Lucas定理的证明为了证明Lucas定理，我们先给出一个定理和一个引理： 定理：若$p$为素数，则对于任意的$\\alpha \\ge 1$和$0 &lt; k &lt; p^{\\alpha}$，有： {\\large \\tbinom{p^{\\alpha}}{k} \\equiv 0 \\quad (mod \\;\\; p)} 证明如下： 根据组合数的定义我们很容易得到： {\\large k \\tbinom{p^{\\alpha}}{k} = p^\\alpha \\tbinom{p^\\alpha - 1}{k - 1}}因为$0 &lt; k &lt; p^\\alpha$，所以$p \\mid k$的最大次幂最多为$p^{\\alpha - 1}$。因此$p \\mid \\tbinom{p^\\alpha}{k}$。证毕。 对于两个整系数多项式$f(x) = \\sum{n \\ge 0}a_nx^n$和$g(x) = \\sum{n \\ge 0}b_nx^n$，若他们多项式中的每一项模$p$均同余，则它们模$p$同余。具体来说，若对于所有的$n \\ge 0$，$a_n \\equiv b_n \\; (mod \\;p)$，则$f(x) \\equiv g(x) \\; (mod \\; p)$。例如： {\\large x^4 + 4x^3 + 6x^2 + 4x + 1 \\equiv x^4 + 1 \\quad (mod \\;\\; 2)}下面给出一个引理： 若$p$为素数，$\\alpha \\ge 0$，则： {\\large (1 + x)^{p^{\\alpha}} = \\sum_{k = 0}^{p^\\alpha} \\tbinom{p^\\alpha}{k} \\equiv 1 + x^{p^\\alpha} \\quad (mod \\;\\; p)} 证明如下： 由二项式定理得： {\\large (1 + x)^{p^\\alpha} = \\sum_{k = 0}^{p^\\alpha} \\tbinom{p^\\alpha}{k}x^k}将该式右边展开可得： {\\large \\tbinom{p^\\alpha}{0}\\cdot 1 + \\tbinom{p^\\alpha}{1} \\cdot x + \\cdots + 1 \\cdot x^{p^\\alpha}}根据上面我们给出的定理易得，除了$k = 0$以及$k = p^\\alpha$的情况，其他情况下展开式的一项对$p$取模均为$0$。即： {\\large \\tbinom{p^\\alpha}{0}\\cdot 1 + \\tbinom{p^\\alpha}{1} \\cdot x + \\cdots + 1 \\cdot x^{p^\\alpha} \\equiv 1 + x^{p^\\alpha} \\quad (mod \\;\\; p)}下面，我们举一个例子来证明Lucas定理： 当$n = 97$，$p = 5$时，由二项式定理可得，$\\tbinom{97}{k}$是$(1 + x)^{97}$的展开式中$x^k$的系数。由引理可得，当$p = 5$时，有： {\\large \\begin{array}{l} (1 + x)^{97} & = & (1 + x)^{3 \\cdot 25}(1 + x)^{4 \\cdot 5}(1 + x)^{2 \\cdot 1} \\\\ & = & (1 + x)^{25}(1 + x)^{25}(1 + x)^{25}(1 + x)^5(1 + x)^5 \\times \\\\ & & (1 + x)^5(1 + x)^5(1 + x)(1 + x) \\\\ & = & (1 + x^{25})(1 + x^{25})(1 + x^{25})(1 + x^5)(1 + x^5) \\times \\\\ & & (1 + x^5)(1 + x^5)(1 + x^1)(1 + x^1) \\quad (mod \\;\\; p) \\end{array}}因此，$\\tbinom{97}{k}$与最后一个表达式$x^k$的系数模$5$同余。 假如$k = 35$，则在最后的表达式中$x^{35}$的系数可以表示为从$3$个不同的$25$，$4$个$5$，$2$个$1$中得到$35$的方法数。因为$35 = 1 \\times 25 + 2 \\times 5 + 0 \\times 1$，所以总共有$\\tbinom{3}{1}\\tbinom{4}{2}\\tbinom{2}{0}$种组合方式。因此$\\tbinom{97}{35} \\equiv \\tbinom{3}{1}\\tbinom{4}{2}\\tbinom{2}{0} \\; (mod \\; p)$ ，至此Lucas定理得证。 Lucas定理等价式的证明我们观察Lucas定理的定义式： {\\large C_n^m \\equiv \\prod_{i = 0}^{k}C_{n_i}^{m_i} \\quad mod \\;\\; p}因为$n_i, m_i$均为$n, m$的$p$进制拆分的某一项，所以根据秦九韶算法，$n, m$可以表示成下面的多项式： {\\large \\begin{array}{l} f(x) & = & a_nx^n + a_{n - 1}x^{n - 1} + \\cdots + a_1x + a_0 \\\\ & = & (a_nx^{n - 1} + a_{n - 1}x^{n - 2} + \\cdots + a_2x + a_1)x + a_0 \\\\ & = & ((a_nx^{n - 2} + a_{n - 1}x^{n - 3} + \\cdots + a_3x + a_2)x + a_1)x + a_0 \\\\ & \\vdots & \\\\ & = & (\\cdots((a_nx + a_{n - 1})x + a_{n - 2})x + \\cdots + a_1)x + a_0 \\end{array}}因此，我们可以将Lucas定理求解的过程转化成为一个递归的过程。即： {\\LARGE \\ \\tbinom{n}{m} = \\tbinom{n / p}{m / p} \\times \\tbinom{n \\; mod \\; p}{m \\; mod \\; p} }至此，Lucas定理及其等价式的证明完毕。","categories":[{"name":"数论","slug":"数论","permalink":"https://mgisr.github.io/categories/%E6%95%B0%E8%AE%BA/"}],"tags":[{"name":"数论","slug":"数论","permalink":"https://mgisr.github.io/tags/%E6%95%B0%E8%AE%BA/"}]},{"title":"乘法逆元.md","slug":"乘法逆元","date":"2021-04-16T01:32:36.000Z","updated":"2021-04-16T12:41:40.741Z","comments":true,"path":"2021/04/16/乘法逆元/","link":"","permalink":"https://mgisr.github.io/2021/04/16/%E4%B9%98%E6%B3%95%E9%80%86%E5%85%83/","excerpt":"乘法逆元什么是逆元 模逆元也称为模倒数，或者模逆元。 一个整数$a$在模$n$意义下的逆元是指满足以下公式的整数$b$。 {\\large a^{-1} \\equiv b \\quad (mod \\;\\; n)}也可以写成以下的式子 {\\large ab \\equiv 1 \\quad (mod \\;\\; n)}或者 {\\large ab \\;\\; mod \\;\\; n = 1}","text":"乘法逆元什么是逆元 模逆元也称为模倒数，或者模逆元。 一个整数$a$在模$n$意义下的逆元是指满足以下公式的整数$b$。 {\\large a^{-1} \\equiv b \\quad (mod \\;\\; n)}也可以写成以下的式子 {\\large ab \\equiv 1 \\quad (mod \\;\\; n)}或者 {\\large ab \\;\\; mod \\;\\; n = 1} 对于一个整数$a$，它在模$n$意义下的逆元存在的充分必要条件是$gcd(a, n) = 1$，若此逆元存在，在模$n$意义下的除法可以用和对应的模拟元的乘法来达成，此概念和实数除法的概念相同。 ​ ——摘自wikipedia《模逆元》 维基百科中对于模逆元的解释已经十分详细，在此需要特别指出的是$0$没有模逆元。不难发现的是，$a$在模$n$意义下的逆元均为$[1, n - 1]$中的整数。 逆元的求法1.扩展欧几里得算法1.线性同余方程扩展欧几里得算法的最初是用来求解线性同余方程 {\\large ax \\equiv c \\; (mod \\;\\; b)}的解。 引理：对于方程$ax \\equiv c \\; (mod \\; b)$，其等价于方程$ax + by = c$，其中$y = {\\left \\lfloor \\frac{c}{b} \\right \\rfloor - \\left \\lfloor \\frac{ax}{b} \\right \\rfloor }$ 证明： 原方程可化为： {\\large ax \\; mod \\; c \\; = \\; b \\; mod \\;c}由模的定义$(a \\; mod \\; b = a - b \\times \\left \\lfloor \\frac{a}{b} \\right \\rfloor)$得： {\\large ax - b \\times \\left \\lfloor \\frac{ax}{b} \\right \\rfloor = c - b \\times \\left \\lfloor \\frac{c}{b} \\right \\rfloor}移项合并同类项得： {\\large ax + (\\left \\lfloor \\frac{c}{b} \\right \\rfloor - \\left \\lfloor \\frac{ax}{b} \\right \\rfloor )b = c}令$y = \\left \\lfloor \\frac{c}{b} \\right \\rfloor - \\left \\lfloor \\frac{ax}{b} \\right \\rfloor$，即可得$ax + by = c$，从而得证。 2.判断方程有整数解的条件 引理：方程$ax + by = c$有整数解的充要条件是$gcd(a, b) \\mid c$ （即$a, b$的最大公约数可以整除$c$） 在证明该命题之前，我们先证明如下定理： 裴蜀定理：对于$\\forall a, v \\in Z, \\exists x, y \\in Z $使得$ax + by = gcd(a, b)$ 证明： 首先，显然有$gcd(a, b) \\mid a, gcd(a, b) \\mid b$。由整除的性质可知$\\forall x, y \\in Z, gcd(a, b) \\mid (ax + by)$。令$s = (ax + by)_{min}, (ax + by) &gt; 0$，因此$gcd(a, b) \\mid s$。 设$k = \\left \\lfloor \\frac{a}{s} \\right \\rfloor$，$r = a \\; mod \\; s$，则有： {\\large \\begin{array}{c} r & = & a - k \\times(ax + by) \\\\ & = & a(1 - kx) + b(-ky) \\end{array}}不妨令$x’ = 1 - kx, y’ = -ky$，原式换元得： {\\large \\begin{array}{c} r & = & ax' + by',\\; (x' \\in \\mathbb{Z}, y' \\in \\mathbb{Z}) \\end{array}}由于： {\\large\\begin{array}{c} s & = & (ax + by)_{min}, \\; (ax + ay) > 0 \\\\ r & = & (ax + by) \\\\ r & \\in & [0, s - 1] \\end{array}}所以$r \\equiv 0$，所以$s \\mid a$，同理可得$s \\mid b$。 因为$s$既是$a$的约数，也是$b$的约数，所以$s \\mid gcd(a, b)$。因为上文中有$gcd(a, b) \\mid s$，故$s = gcd(a, b)$。进而可证方程$ax + by = gcd(a, b)$一定有解。 下面考虑将$ax + by = gcd(a,b)$推广到$ax + by = c$的形式，为了区分两者，我们将前式中的$a, b$分别用$a’, b’$替换。则可得到： {\\large a'x + b'y = gcd(a', b')}令$k = gcd(a’,b’)$，方程两边同除$k$可得： {\\large \\frac{a'}{k}x + \\frac{b'}{k}y = 1}方程两边同乘$c$得： {\\large \\frac{a'c}{k}x + \\frac{b'c}{k}y = c}通过换元，令$a = \\frac{a’c}{k},b = \\frac{b’c}{k}$。则原式可化为： {\\large ax + by = c}由于$gcd(\\frac{a’c}{k}, \\frac{b’c}{k}) = c = gcd(a, b)$，且对于一般的方程 {\\large atx + aty = c' \\; (c' = ct, t \\in Z)}故当且仅当$gcd(a, b) \\mid c$时原方程有解，从而得证。 3.方程的解法（扩展欧几里得算法）现在的问题是求解如下的方程： {\\large ax + by = c}我们不妨先看它的特殊形式： {\\large a'x + b'y = gcd(a',b')}根据欧几里得算法可得$gcd(a, b) = gcd(b, a \\; mod \\; b)$ 故有： {\\large \\begin{array}{C} a'x + b'y & = & gcd(a', b') \\\\ & = & gcd(b', a' \\; mod \\;b') \\\\ & = & b'x + (a' \\; mod \\; b')y \\\\ & = & b'x + (a' - \\frac{a'}{b'} \\times b')y \\\\ & = & a'y + b'(x - \\frac{a'}{b'} \\times y) \\end{array}}通过换元，令$x’ = y, y’ = x - \\frac{a’}{b’} \\times y$。即可得到一个新的方程： {\\large a'x' + a'y' = gcd(a', b')}将此方程继续迭代，直到$b’ = 0$时，得到$x’ = 1, y’ = 0$，再向上递推即可得出原方程得一个特解。 假设我们解出了方程$a’x + b’y = gcd(a’, b’)$的一组特解为$x_0, y_0$，从上文可知$a = \\frac{a’c}{gcd(a’, b’)}, b = \\frac{b’c}{gcd(a’, b’)}$，故原方程的解为： {\\large x = \\frac{x_0c}{gcd(a', b')}}下面给出扩展欧几里得算法的伪代码： {\\large\\begin{array}{1} \\text{EXGCD}(a, b, x, y) \\\\ \\begin{array}{2} 1 & \\textbf{if } \\; b == 0 \\\\ 2 & \\qquad x \\gets 1, y \\gets 0 \\\\ 3 & \\qquad \\textbf{return} \\; a \\\\ 4 & d \\gets EXGCD(b, a \\% b, y, x) \\\\ 5 & y \\gets y - a / b *x \\\\ 6 & \\textbf{return} \\; d \\end{array} \\end{array}}4.求逆元观察逆元的定义式： {\\large ax \\equiv 1 \\; (mod \\;\\; p)}上式可化为： {\\large ax \\; mod \\; p = 1 \\;\\; mod \\;\\; p}移项得： {\\large (ax - 1) \\; mod \\; p = 0}由上式可知$p \\mid (ax - 1)$，不妨设： {\\large ax - 1 = kp, (k \\in Z)}移项得： {\\large ax - kp = 1}令$y = -k$，得： {\\large ax + py = 1}这就回到了上面所说的线性同余方程求解的问题。 由上面的分析可知，$ax + py = 1$有解的条件是$gcd(a, p) \\mid 1$，即$gcd(a, p) = 1$。 因为$gcd(a, p) = 1$，所以我们可以直接利用扩展欧几里得算法求$ax + py = gcd(a, p)$的解。 该算法的时间复杂度为$O(log^p)$ 2.欧拉定理下面给出逆元的定义式与欧拉定理的定义式： {\\large \\begin{array}{C} ax \\equiv 1 \\quad(mod \\;\\; p) \\\\ a^{\\varphi (p)} \\equiv 1 \\quad (mod \\;\\; p) \\end{array}}而两者成立的条件均为$gcd(a, p) = 1$，所以可以将两式合并： {\\large ax \\equiv a^{\\varphi (p)} \\quad (mod \\;\\; p)}两边同除$a$得： {\\large x \\equiv a^{\\varphi (p) - 1} \\quad (mod \\;\\; p)}故$x = {a^{\\varphi (p) - 1}} \\; mod \\;p$ 我们$O(\\sqrt p)$的时间内求出单个数的欧拉函数。 引理：设 $ n = p{1}^{k_1} \\times p{2}^{k2} \\times \\cdots \\times p{m}^{km} = \\prod{i = 1}^{m} p_{i}^{k_i} $ 为正整数 $ n $ 的质数幂乘积表示式， 则： {\\varphi (n) = n \\times (1 - {\\frac{1}{p_1}}) \\times (1 - {\\frac{1}{p_2}}) \\times \\cdots \\times (1 -{ \\frac{1}{p_m}}) = n \\times \\prod_{i = 1}^{m}(1 - {\\frac{1}{p_i}})} 证明如下： 在证明该定理之前，我们先给出另一个引理： 设$p$为任意质数，那么$\\varphi(p^k) = p^{k - 1} \\times (p - 1)$。 证明：显然对于$[1, p^k]$范围内的数，除了$p^{k - 1}$个$p$的倍数以外其他数都与$p^k$互素，故$\\varphi(p^k) = p^k - p^{k - 1} = p^{k - 1} \\times (p - 1)$，证毕。 接下来我们来证明\\varphi(n) = n \\times \\prod_{i = 1}^{s} \\frac{p_i - 1}{p_i}。由唯一分解定理与$\\varphi(x)$函数的积性可得： {\\large \\begin{eqnarray} \\varphi(n) & = & \\prod_{i = 1}^{s} \\varphi(p_i^{k_i}) \\\\ & = & \\prod_{i = 1}^{s} (p_i - 1) \\times p_i^{k_i - 1} \\\\ & = & \\prod_{i = 1}^{s} p_i^{k_i} \\times (1 - \\frac{1}{p_i}) \\\\ & = & n \\times \\prod_{i = 1}^{s}(1 - \\frac{1}{p_i}) \\end{eqnarray}}下面给出欧拉函数的伪代码： {\\large \\begin{array}{1} \\text{EULER_PHI(n)} \\\\ \\begin{array}{2} 1 & ans \\gets n \\\\ 2 & \\textbf{for} \\;\\; i \\gets 2 \\;\\; to \\;\\; \\sqrt{n} \\\\ 3 & \\qquad \\textbf{if} \\;\\; n \\;\\; mod \\;\\;i \\; = \\;0 \\\\ 4 & \\qquad \\qquad ans \\gets \\frac{ans \\times (i - 1)}{i} \\\\ 5 & \\qquad \\qquad \\textbf{while} \\;\\; n \\;\\; mod \\;\\;i \\; = \\;0 \\\\ 6 & \\qquad \\qquad \\qquad n \\gets \\frac{n}{i} \\\\ 7 & \\qquad \\textbf{if} \\;\\; n > 1 \\\\ 8 & \\qquad \\qquad ans \\gets \\frac{ans \\times (n - 1)}{n} \\\\ 9 & \\textbf{return} \\;\\; ans \\end{array} \\end{array}}由上面我们推出的式子$x = a^{\\varphi(p) - 1} \\; mod \\; p$，结合快速幂算法。就可以在$O(log \\varphi(p) + \\sqrt p)$的复杂度下求出逆元。 3.费马小定理特别提示：费马小定理求逆元仅适用于$p$为质数的情况 费马小定理：若$p$为质数，且整数$a$满足$p \\nmid a$，则有$a^{p - 1} \\equiv 1 \\;\\;(mod \\;\\; p)$ 对于定理中的式子，我们可以将两边同除$a$，可得： {\\large a^{p - 2} \\equiv a^{-1} \\quad (mod \\;\\; p)}而$a^{-1}$就是$a$在模$p$的意义下的乘法逆元。 因此我们只需要计算$a^{p - 2} \\; mod \\; p$即可，而这个问题可以使用快速幂解决。 分数取模我们先来观察分数取模的一般形式： {\\large \\frac{a}{b} \\;\\; mod \\;\\; p}我们假设它的值为$x$，则易得： {\\large bx \\equiv a \\;\\; (mod \\;\\; p), x \\in [0, p - 1]}两边同乘$b$在模$p$意义下的乘法逆元$b^{-1}$可得： {\\large x \\equiv ab^{-1} \\quad (mod \\;\\; p)}而$x$的取值范围在模$p$的剩余系$[0, p - 1]$当中，故上式可直接写作： {\\large x = ab^{-1} \\; mod \\;\\; p}4.线性求逆元注意，这种方法仅适用于模数$p$为质数时 基于扩展欧几里得算法，我们可以在$O(nlog\\;p)$的时间内求出$[1, n], {1 \\le n \\le p}$中所有整数在模$p$意义下的乘法逆元，但如果数据范围继续扩大，那我们就不能忽略$log\\; p$所带来的影响了。这时，我们就需要复杂度更低的算法。 首先，我们不难发现的是，对于任意的正整数$p$， $1 \\equiv 1^{-1} \\quad (mod \\; p)$，即$1$的逆元始终为$1$。 然后我们设$p = ki + r\\;(r &lt; i, 1 &lt; i &lt; p, k \\in Z)$，转化为同余式可得： {\\large ki + r \\equiv 0 \\quad (mod \\;\\; p)}两边同乘$i^{-1},r^{-1}$，得： {\\large i^{-1}r^{-1}(ki + r) \\equiv 0 \\quad (mod \\;\\;p)}将上式展开得： {\\large kr^{-1} + i^{-1} \\equiv 0 \\quad (mod \\;\\; p)}移项得： {\\large i^{-1} \\equiv -kr^{-1} \\quad (mod \\;\\; p)}由$p = ki + r$易得$k = \\left \\lfloor \\frac{p}{i} \\right \\rfloor, r = p \\; mod \\; i$，故： {\\large i^{-1} \\equiv -\\left \\lfloor \\frac{p}{i} \\right \\rfloor \\times (p \\;\\;mod \\;\\; i)^{-1} \\quad (mod \\;\\; p)}而$p \\; mod \\; i &lt; i$，所以$(p \\; mod \\; i)^{-1}$的值我们已经递推过了，所以我们可以通过这个式子推出$i$的逆元$i^{-1}$。 综上，因为我们已经知道了$1$的逆元固定为$1$。所以，我们可以在$O(n)$的时间内推出$[1,n],(1 \\le n &lt; p)$中所有整数的乘法逆元。 因为$-\\left \\lfloor \\frac{p}{i} \\right \\rfloor$为负数，但在模$p$意义下，它等价于$p -\\left \\lfloor \\frac{p}{i} \\right \\rfloor$，因此实际应用中的递推式为： {\\large i^{-1} \\equiv (p -\\left \\lfloor \\frac{p}{i} \\right \\rfloor) \\times (p \\;\\;mod \\;\\; i)^{-1} \\quad (mod \\;\\; p)}5.离线逆元在学习离线逆元之前，我们先来介绍一下它的用途。 前面我们已经学过了很多种逆元的求法，其中还包括了时间复杂度十分优秀的线性求逆。但我们考虑这样一个问题，如果我们要对$n$个离散的整数$a_1, a_2, \\cdots a_n$求逆元的话，按照我们之前学过的知识，可以有一个$O(nlog \\; n)$的算法，或者一个$O(max(a_i))$的算法。 但如果这两种算法都不能在理想的时间内得到正确的结果的话，我们就要考虑更优的解决方案。 在给出离线逆元的算法之前，我们先证明一个后面需要用到的引理。 引理：逆元是完全积性的。也就是说逆元的积等于积的逆元。 也就是说，我们要证明对于任意的正整数$a, b$，在模$p$意义下满足： {\\large a^{-1} \\times b^{-1} \\equiv (ab)^{-1} \\quad (mod \\;\\; p)}根据逆元的定义可得： {\\large \\begin{array}{C} a \\times a^{-1} &\\equiv& 1 \\quad (mod \\;\\; p) \\\\ b \\times b^{-1} &\\equiv& 1 \\quad (mod \\;\\; p) \\end{array}}两式相乘得： {\\large a \\times b \\times a^{-1} \\times b^{-1} \\equiv 1 \\quad (mod \\;\\; p)}不难看出$a^{-1} \\times b^{-1}$与$(ab)^{-1}$在模$p$意义下相同，因此： {\\large a^{-1} \\times b^{-1} \\equiv (ab)^{-1} \\quad (mod \\;\\; p)}命题得证。 再来看离线逆元的问题，我们引出一个变量$pre_i$，用来表示$a_1 \\cdots a_i$得前缀积，即： {\\large pre_i = \\prod_{j = i}^{i} a_j}我们用费马小定理求出$pre_n$的逆元$pre_n^{-1}$，由于逆元是完全积性的，所以： {\\large pre_n^{-1} \\equiv a_1^{-1} \\times a_2^{-1} \\times \\cdots \\times a_n^{-1} \\quad (mod \\;\\; p)}现在我们要求某一项$a_i^{-1}$的值，根据上式易得： {\\large a_i^{-1} = pre_{i - 1} \\times pre_i^{-1} = \\prod_{j = 1}^{i - 1} a_j \\times \\prod_{j = 1}^{i}a_j^{-1}}在求出$pre_n……{-1}$后，易得一个$pre_i$的递推式： {\\large pre_i = a_{i + 1} \\times pre_{i + 1}^{-1}}所以我们可以预处理出所有的$pre_i……{-1}$，然后利用$a_i^{-1}$的递推式即可求出每一项的逆元。 综上，可以得到递推式为： {\\large \\begin{eqnarray} pre_i & = & a_{i + 1} \\times pre_{i + 1}^{-1} & \\quad (1 \\le i < n)\\\\ a_i^{-1} & = & pre_{i - 1} \\times pre_i^{-1} & \\quad (1 \\le j \\le n) \\end{eqnarray}}特别的$pre_1 = 1$。 因此我们可以在$O(n + log\\;p)$的时间内求出$n$个离散整数的逆元。","categories":[{"name":"数论","slug":"数论","permalink":"https://mgisr.github.io/categories/%E6%95%B0%E8%AE%BA/"}],"tags":[{"name":"数论","slug":"数论","permalink":"https://mgisr.github.io/tags/%E6%95%B0%E8%AE%BA/"}]},{"title":"PyCharm安装","slug":"PyCharm安装","date":"2021-03-05T00:20:30.000Z","updated":"2021-04-27T09:29:37.161Z","comments":true,"path":"2021/03/05/PyCharm安装/","link":"","permalink":"https://mgisr.github.io/2021/03/05/PyCharm%E5%AE%89%E8%A3%85/","excerpt":"下载PyCharm&emsp;&emsp;在搜索引擎中搜索JetBrains官网，进入到官网后，选择上方的Developer Tools，从出现的界面中选择PyCharm点击。在弹出的界面中点击Download。等待下载完成后，一路next安装即可。","text":"下载PyCharm&emsp;&emsp;在搜索引擎中搜索JetBrains官网，进入到官网后，选择上方的Developer Tools，从出现的界面中选择PyCharm点击。在弹出的界面中点击Download。等待下载完成后，一路next安装即可。 配置PyCharm&emsp;&emsp;首次启动时000，会出现如下的界面。登陆你的JetBrains账户验证即可，基本上学校都会有教育邮箱，可以在JetBrains官网申请免费的教育许可证。 &emsp;&emsp;验证通过后，点击new project。这时会进入项目界面，点击右上角的File-&gt;Settings-&gt;Plugins。搜索Chinese，选择下图中的插件安装，然后重启即可更改为中文界面。 &emsp;&emsp;如果你的电脑上没有安装Python环境的话，请点击文件-&gt;设置-&gt;项目:XXXXXX-&gt;Python解释器。在如下位置会出现下载的提示，根据提示下载即可。 &emsp;&emsp;一切配置完成后，首次运行代码时需要点击如下位置。然后在弹出的界面中选择main配置即可。","categories":[{"name":"Python笔记","slug":"Python笔记","permalink":"https://mgisr.github.io/categories/Python%E7%AC%94%E8%AE%B0/"},{"name":"第一章","slug":"Python笔记/第一章","permalink":"https://mgisr.github.io/categories/Python%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AB%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://mgisr.github.io/tags/Python/"}]},{"title":"模式匹配算法选讲","slug":"模式匹配算法选讲","date":"2021-02-18T20:24:22.000Z","updated":"2021-03-05T01:22:49.150Z","comments":true,"path":"2021/02/19/模式匹配算法选讲/","link":"","permalink":"https://mgisr.github.io/2021/02/19/%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95%E9%80%89%E8%AE%B2/","excerpt":"引言&emsp;&emsp;字符串的模式匹配一直是一个令人头疼的问题，在最初的时候，对于字符串的模式匹配一直是采用暴力法进行匹配的。这种匹配方法简单有效，几乎不会出任何差错，但唯一的缺点就是效率太低了。对于两个字符串$A,B$来说，假设它们的长度分别为$n,m$，则朴素算法的时间复杂度的上界会达到$n \\times m$。这个时间复杂度在$n,m$较小时还可以接受但是，实际中需要处理的字符串往往非常的长，这时候再采用这种朴素算法似乎就行不通了。","text":"引言&emsp;&emsp;字符串的模式匹配一直是一个令人头疼的问题，在最初的时候，对于字符串的模式匹配一直是采用暴力法进行匹配的。这种匹配方法简单有效，几乎不会出任何差错，但唯一的缺点就是效率太低了。对于两个字符串$A,B$来说，假设它们的长度分别为$n,m$，则朴素算法的时间复杂度的上界会达到$n \\times m$。这个时间复杂度在$n,m$较小时还可以接受但是，实际中需要处理的字符串往往非常的长，这时候再采用这种朴素算法似乎就行不通了。 &emsp;&emsp;对于朴素算法来说，该算法对于模式串的信息并没有好好利用。事实上，我们可以通过对模式串进行预处理来节省非常多的时间。因此，下面介绍的模式匹配算法都在匹配之前对模式串进行了预处理，所以这些算法的时间复杂度将由两部分组成，一部分是对模式串进行预处理所需的时间，另一部分是将模式串与文本串进行匹配所需的时间。 &emsp;&emsp;首先我们要研究的是Rabin和Karp提出的Rabin-Karp算法，在实际的应用中该算法能够较好的运行。Rabin-Karp算法的预处理时间是$\\Theta(m)$，这基本上是基于预处理模式串算法的通用复杂度。在最坏的情况下，该算法的时间复杂度为$\\Theta((n - m + 1)m)$。这是理论上的最坏时间复杂度，但基于一些假设，在平均情况下，它的运行时间还是比较好的。 &emsp;&emsp;上面所说的Rabin-Karp算法已经能够较好的处理大部分的问题，但为了进一步的优化时间效率，一种基于有限自动机的字符串匹配算法出现了，这种算法具有$\\Theta (\\sum \\times m)$的预处理时间，以及$O(n)$的匹配时间。 &emsp;&emsp;为了降低有限自动机算法的预处理时间，从而得到更高效的模式匹配算法，世界上很多专家进行了非常多的努力。终于，在1977年Donald Knuth、Vaughan Pratt、James H. Morri三人联合发表了一篇文章。文章中提出了一种时间复杂度为$\\Theta (n + m)$的模式匹配算法，为了纪念这三个人的贡献，所以该算法取他们三人名字的首字母命名，称之为KMP算法。 &emsp;&emsp;同样是在1977年，德克萨斯大学的Robert S. Boyer教授和J Strother Moore教授发明了一种新的字符串匹配算法：Boyer-Moore算法，简称BM算法。该算法从模式串的尾部开始匹配，且拥有在最坏情况下$O(n)$的时间复杂度。在实践中，比KMP算法的实际效能高。 &emsp;&emsp;而在Boyer-Moore算法发明的13年后的1990年，一种更加快速的字符串匹配算法由Daniel M.Sunday提出了。该算法被称之为Sunday算法。该算法与Boyer-Moore算法的时间复杂度相同，但在实际应用中，比Boyer-Moore算法的效率要高一些。 Rabin-Karp算法&emsp;&emsp;RK算法的基本思想就是将文本串中所有的长度为$m$的共$n-m+1$个字串转化为十进制数字，通过适当的散列函数将其散列。然后求出模式串的散列函数值，通过函数值之间的比较，来得知两个字符串是否相同。 &emsp;&emsp;最简单的散列函数当然是将字符串当作一个数字，按照进制转换的方法将其转换为一个十进制数字。这样做的优点是不会产生冲突，所以所有的匹配都只会耗费$O(n)$的时间。这也是该算法理想的最优复杂度。但这样做的缺点也很明显，当文本串过长的时候，使用该方法得到的散列函数值会非常的巨大，大到超过计算机语言所允许的最大值，从而导致溢出。 &emsp;&emsp;所以，为了解决这个问题，我们只能改变散列函数，对于散列函数的选取有很多很多的方法。这里不做赘述。要注意的是该算法的时间复杂度与散列函数的选取息息相关，如果选择不恰当的散列函数有可能会使该算法的时间复杂度退化到$O(n \\times m)$。 &emsp;&emsp;在产生冲突时，可以用很多很多的方法解决冲突。这时与模式串哈希值相同的文本子串就不一定与模式串相同了，所以还要进行一次比较，看模式串和文本子串是否相匹配。 &emsp;&emsp;下面以文本串$S = “ABCD”$，模式串$T = “CD”$为例，详细的介绍一下RK算法的流程。首先，我们要对文本串$S$中所有长度为$T.length$的子串进行散列。这里我们假定所有字符均为大写字母，然后定义散列函数如下： {\\large \\delta (T) = \\sum _{i = 0}^{T.length - 1} {(T_i - A) \\times 26^{T.length - i - 1}}}&emsp;&emsp;在得到该散列函数后，我们对文本串$S$中所有的长度为$T.length$的子串进行散列。散列结果如下： {\\large \\left.\\begin{matrix} AB\\\\ BC \\\\ CD \\end{matrix}\\right\\} \\stackrel{\\delta (T)}{\\longrightarrow } \\left\\{\\begin{matrix} 1 \\\\ 28 \\\\ 55 \\end{matrix}\\right.}然后，我们对模式串$T = “CD”$散列，得到的结果为$55$。由于采用该散列函数不会冲突，所以我们只需要找到文本串中散列值为$55$的子串即可完成匹配。 基于有限状态自动机的模式匹配算法（DFA）文本匹配的流程&emsp;&emsp;假定目前要查找的字符串$P = ababaca$,文本串为$T = abababacaba$。从$T$中，每次读入一个字符，将读入的字符加入到一个新的字符串$S$中，然后从$P$的第一个字符开始，看连续几个字符所构成的字符串可以成为$S$的后缀，并把这个后缀的长度记为$k$。重复此过程，所以形成的操作序列如下： {\\large \\begin{matrix} &S =& a & k = 1 & P_{1}&是S的后缀\\\\ &S =& ab & k = 2 & P_{12}&是S的后缀\\\\ &S =& aba & k = 3 & P_{123}&是S的后缀\\\\ &S =& abab & k = 4 & P_{1\\dots4}&是S的后缀\\\\ &S =& ababa & k = 5 & P_{1\\dots5}&是S的后缀\\\\ &S =& ababab & k = 4 & P_{1\\dots4}&是S的后缀\\\\ &S =& abababa & k = 5 & P_{1\\dots5}&是S的后缀\\\\ &S =& abababac & k = 6 & P_{1\\dots6}&是S的后缀\\\\ &S =& abababaca & k = 7 & P_{1\\dots7}&是S的后缀\\\\ &S =& abababacab & k = 2 & P_{12}&是S的后缀\\\\ &S =& abababacaba & k = 3 & P_{123}&是S的后缀\\\\ \\end{matrix}}这时我们注意第$9$步，此时$k$的值为$7$，也就是说整个字符串$P$成为了字符串$S$的后缀。由于$S$是由$T$中的字符按顺序组成的，所以，$P$是$S$的后缀，也就说明$P$存在与$T$中，这样也就完成了$P$与$T$的匹配。 &emsp;&emsp;根据朴素算法的匹配过程，我们判断$P$中最多有几个字符可以成为$S$的后缀时，最多需要匹配$m$个字符。所以这一操作的最坏时间复杂度为$O(m)$，加之$T$中有$n$个字符，因此，朴素算法的时间复杂度为$O(nm)$。如果说有某种办法，可以使我们仅用$O(1)$的时间复杂度就可以知道$P$中最多有几个字符可以成为$S$的后缀，那么我们就可以将算法的时间复杂度优化为$O(n)$，因为外层循环最多会被执行$n$次。 &emsp;&emsp;所以，当前要解决的问题就转化成了，构造一个方法，使得一次运行就能知道从$P$的第一个字符开始，最多能连续读取几个字符，使得这几个字符构成的字符串是$S$的后缀。这就要利用到下面提到的有限状态自动机。 什么是有限状态自动机&emsp;&emsp;在研究基于有限状态自动机的模式匹配算法之前，我们先来了解一下有限状态自动机（以下简称$DFA$）一个有限状态自动机$M$是一个五元组${Q,q_0,A,\\sum,\\delta}$，其中： $Q$是状态的有限集合。因为是有限状态自动机，所以他可以接受的状态也是有限的。 $q_0 \\in Q$是初始状态。任何东西都有一个初始值，$DFA$也不例外，$q_0$就是一个初始状态，它表示自动机初始处在的状态。 $A\\subseteq Q$是一个接收状态的集合。也就是说，当你输入的序列最后使$M$达到的状态$t \\in A$时，这个序列才能被$M$所接受。 $\\sum$是一个有限输入字母表。这个表中包含了所有有可能输入的字符，$M$要根据这些字符来确定要跳转到的状态。 $\\delta$是一个从$Q \\times \\sum$到$Q$的函数，称为$M$的转移函数。这里解释一下从$Q \\times \\sum$到$Q$，这里的意思是，当前处在一个状态$a$,然后读入一个$\\sum$中存在的字符，此时$M$会跳转到另一个状态$b$，由于$a,b \\in Q$，所以称为从$Q \\times \\sum$到$Q$。 我们看下面这个图 该图描述的就是一个$DFA$，它的状态集$Q = {0,1}$，输入字母表$\\sum = {a,b}$。图中的有向边代表了状态转移函数$\\delta$，例如从$0$到$1$的一条边值为$a$的边就可以表示为$\\delta(0,a) = 1$。 &emsp;&emsp;一个$DFA$都会有一个初始节点和一个接收节点，以上图为例，我们可以设置初始节点为$0$，接收节点为$1$，当进行一系列的输入，使得$DFA$的状态不断变化，只要最后一个输入使得$DFA$处于接收节点，那么就表明当前输入可以被$DFA$接收。例如对应字符串$abaaa$, 从初始节点$0$开始，$DFA$根据该字符串的输入所形成的状态变化序列为：${0，1，0，1，0，1}$。由于最后$DFA$处于状态$1$，所以该字符串可以被$DFA$接收。如果输入的字符串是:$abbaa$, 那么$DFA$的变化序列为：${0，1，0，0，1，0}$， 由于最后$DFA$处于非接收状态，因此这个字符串被$DFA$拒绝。 &emsp;&emsp;现在我们为有限自动机$M$引入一个函数$\\phi$，称为终态函数，它是从$\\sum^*$到$Q$的函数，$\\phi(\\omega)$表示的是有限自动机$M$在扫描字符串$\\omega$后终止时的状态。例如以上面的有限自动机来说，假设$\\omega = abaaa$，那么$\\phi(\\omega) = 1$。所以，对于一个字符串$\\omega$来说，当且仅当$\\phi(\\omega) \\in A$时，$M$接受字符串$\\omega$。我们可以用转移函数递归定义$\\phi$： {\\large \\begin{matrix} \\phi(\\varepsilon ) & = & q_0\\\\ \\phi(\\omega\\alpha ) & = & \\delta (\\phi(\\omega), \\alpha ) & \\omega \\in \\sum^*, \\alpha \\in \\sum \\end{matrix}}&emsp;&emsp;这里有必要解释一下上面新出现的符号，$\\varepsilon$表示的是空字符串，而在有限字符集$\\sum$右上角加的{*}称为克莱尼星号，\\sum^{*}表示将$\\sum$中的所有字符排列组合可能形成的字符串的集合。 用于字符串匹配的有限状态自动机&emsp;&emsp;对于一个给定的模式串$P$，我们可以在预处理阶段构造出一个字符串匹配有限状态自动机，根据模式串构造出相应的自动机后，再利用它来进行文本字符串的匹配。现在我们假定$P = ababaca$，下面的过程将用$P$来代替，不再重述$P$的依赖关系。 &emsp;&emsp;为了说明与$P$对应的字符串匹配自动机。首先我们先定义一个辅助函数$\\sigma$,称为$P$的后缀函数。函数$\\sigma$是一个从$\\sum^*$到${0,1,\\cdots m}$上的映射，满足$\\sigma(x)$是$x$的后缀$P$的最长前缀的长度： \\large{\\sigma(x) = max\\{k:P_k x\\}}因为空字符串$P_0 = \\varepsilon$是每一个字符串的后缀，所以后缀函数$\\sigma$是良定义的，即： 相同的自变量有相同的函数值 对任意$x \\in \\sum^*$都存在函数值$\\sigma(x)$。 例如，对模式$P = ab$，有$\\sigma(\\varepsilon) = 0,\\sigma(abca) = 1, \\sigma(cbab) = 2$。对于一个长度为$m$的模式$P$，$\\sigma(x) = m$当且仅当$P\\sqsupset x$。根据后缀函数的定义，如果$x \\sqsupset y$，则$\\sigma(x) \\le \\sigma(y)$。 给定模式$p[1, \\cdots, m]$，其对应的字符串匹配自动机定义如下： 状态集合$Q$为${0,1,\\cdots,m}$。开始状态$q_0$是$0$状态，并且只有状态$m$是唯一被接受的状态。 对任意的状态$q$和字符$a$，转移函数定义如下： \\large{\\delta(q,a) = \\sigma(P_qa) } &emsp;&emsp;我们定义$\\delta(q,a) = \\sigma(P_qa)$的目的是，记录已得到的与模式$P$匹配的文本字符串$T$的最长前缀。考虑最近一次读入的$T$的字符。为了使$T$的一个子串(以$T[i]$结尾的子串)能够和$P$的某些前缀$P_j$匹配，前缀$P_j$必须是$T_i$的一个后缀。假设$q = \\phi(T_i)$，那么在读完$T_i$之后，自动机处在状态$q$。设计转移函数$\\delta$，使用状态数$q$来表示$P$的前缀和$T_i$的后缀的最长匹配长度。也就是说，在处于状态$q$时，$P_q \\sqsupset T_i$，并且$q = \\sigma(T_i)$。（每当$q = m$时，$P$中所有的$m$个字符都会和$T_i$的一个后缀匹配，从而得到一个匹配。）因此，由于$\\phi(T_i)$和$\\sigma(T_i)$都和$q$相等，所以在自动机中，下列定理始终成立： \\large{\\phi(T_i) = \\sigma(T_i)}如果自动机处在状态$q$并且读入下一个字符$T[i + 1] = a$，那么我们肯定希望这个转换能够指向$T_ia$的后缀状态，它对应着$P$的最长前缀，并且这个状态是$\\sigma(T_ia)$。由于","categories":[{"name":"算法","slug":"算法","permalink":"https://mgisr.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"字符串","slug":"字符串","permalink":"https://mgisr.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]}],"categories":[{"name":"算法","slug":"算法","permalink":"https://mgisr.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"数论","slug":"数论","permalink":"https://mgisr.github.io/categories/%E6%95%B0%E8%AE%BA/"},{"name":"Python笔记","slug":"Python笔记","permalink":"https://mgisr.github.io/categories/Python%E7%AC%94%E8%AE%B0/"},{"name":"第一章","slug":"Python笔记/第一章","permalink":"https://mgisr.github.io/categories/Python%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AB%A0/"}],"tags":[{"name":"数论","slug":"数论","permalink":"https://mgisr.github.io/tags/%E6%95%B0%E8%AE%BA/"},{"name":"Python","slug":"Python","permalink":"https://mgisr.github.io/tags/Python/"},{"name":"字符串","slug":"字符串","permalink":"https://mgisr.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]}